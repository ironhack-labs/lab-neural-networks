{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Tic Tac Toe\n",
    "\n",
    "In this lab you will perform deep learning analysis on a dataset of playing [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
    "\n",
    "There are 9 grids in Tic Tac Toe that are coded as the following picture shows:\n",
    "\n",
    "![Tic Tac Toe Grids](tttboard.jpg)\n",
    "\n",
    "In the first 9 columns of the dataset you can find which marks (`x` or `o`) exist in the grids. If there is no mark in a certain grid, it is labeled as `b`. The last column is `class` which tells you whether Player X (who always moves first in Tic Tac Toe) wins in this configuration. Note that when `class` has the value `False`, it means either Player O wins the game or it ends up as a draw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps suggested below to conduct a neural network analysis using Tensorflow and Keras. You will build a deep learning model to predict whether Player X wins the game or not.\n",
    "\n",
    "## Step 1: Data Engineering\n",
    "\n",
    "This dataset is almost in the ready-to-use state so you do not need to worry about missing values and so on. Still, some simple data engineering is needed.\n",
    "\n",
    "1. Read `tic-tac-toe.csv` into a dataframe.\n",
    "1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
    "1. Convert the categorical values to numeric in all columns.\n",
    "1. Separate the inputs and output.\n",
    "1. Normalize the input data."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:51:59.893236Z",
     "start_time": "2024-09-23T12:51:59.876349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:38:19.974069Z",
     "start_time": "2024-09-23T12:38:19.737898Z"
    }
   },
   "source": [
    "data = pd.read_csv(\"tic-tac-toe.csv\")\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  TL TM TR ML MM MR BL BM BR  class\n",
       "0  x  x  x  x  o  o  x  o  o   True\n",
       "1  x  x  x  x  o  o  o  x  o   True\n",
       "2  x  x  x  x  o  o  o  o  x   True\n",
       "3  x  x  x  x  o  o  o  b  b   True\n",
       "4  x  x  x  x  o  o  b  o  b   True"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:38:24.299802Z",
     "start_time": "2024-09-23T12:38:24.145106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categorical = data.select_dtypes(exclude='number')\n",
    "for column in list(categorical):\n",
    "    data[column] = LabelEncoder().fit_transform(data[column])"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:38:25.196397Z",
     "start_time": "2024-09-23T12:38:25.162805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data.drop(columns=['class'])\n",
    "y = data['class']"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build Neural Network\n",
    "\n",
    "To build the neural network, you can refer to your own codes you wrote while following the [Deep Learning with Python, TensorFlow, and Keras tutorial](https://www.youtube.com/watch?v=wQ8BIBpya2k) in the lesson. It's pretty similar to what you will be doing in this lab.\n",
    "\n",
    "1. Split the training and test data.\n",
    "1. Create a `Sequential` model.\n",
    "1. Add several layers to your model. Make sure you use ReLU as the activation function for the middle layers. Use Softmax for the output layer because each output has a single lable and all the label probabilities add up to 1.\n",
    "1. Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
    "1. Fit the training data.\n",
    "1. Evaluate your neural network model with the test data.\n",
    "1. Save your model as `tic-tac-toe.model`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:38:26.554453Z",
     "start_time": "2024-09-23T12:38:26.442075Z"
    }
   },
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:38:27.333690Z",
     "start_time": "2024-09-23T12:38:27.280430Z"
    }
   },
   "cell_type": "code",
   "source": "model = Sequential()",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:38:28.074767Z",
     "start_time": "2024-09-23T12:38:27.895624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input layer: Matches the size of your input data (flattened Tic-Tac-Toe board)\n",
    "model.add(Dense(40, activation='relu')) \n",
    "\n",
    "# Hidden layer(s): Experiment with the number of neurons and layers\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "\n",
    "# Output layer: Number of neurons = number of classes (possible outcomes in Tic-Tac-Toe)\n",
    "model.add(Dense(3, activation='softmax')) "
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:38:29.191035Z",
     "start_time": "2024-09-23T12:38:28.492814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:39:47.599207Z",
     "start_time": "2024-09-23T12:38:29.526947Z"
    }
   },
   "cell_type": "code",
   "source": "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test)) ",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 78ms/step - accuracy: 0.6320 - loss: 0.9626 - val_accuracy: 0.6562 - val_loss: 0.7081\n",
      "Epoch 2/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - accuracy: 0.6732 - loss: 0.6609 - val_accuracy: 0.6615 - val_loss: 0.6276\n",
      "Epoch 3/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - accuracy: 0.6413 - loss: 0.6288 - val_accuracy: 0.6615 - val_loss: 0.6031\n",
      "Epoch 4/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - accuracy: 0.6599 - loss: 0.6099 - val_accuracy: 0.6615 - val_loss: 0.6008\n",
      "Epoch 5/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - accuracy: 0.6717 - loss: 0.5977 - val_accuracy: 0.7448 - val_loss: 0.5701\n",
      "Epoch 6/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - accuracy: 0.7443 - loss: 0.5536 - val_accuracy: 0.7552 - val_loss: 0.5474\n",
      "Epoch 7/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - accuracy: 0.7405 - loss: 0.5612 - val_accuracy: 0.7708 - val_loss: 0.5291\n",
      "Epoch 8/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - accuracy: 0.7656 - loss: 0.5182 - val_accuracy: 0.7708 - val_loss: 0.5161\n",
      "Epoch 9/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7633 - loss: 0.4990 - val_accuracy: 0.7708 - val_loss: 0.4790\n",
      "Epoch 10/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - accuracy: 0.7882 - loss: 0.4662 - val_accuracy: 0.8125 - val_loss: 0.4461\n",
      "Epoch 11/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - accuracy: 0.8094 - loss: 0.4407 - val_accuracy: 0.8125 - val_loss: 0.4476\n",
      "Epoch 12/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - accuracy: 0.8206 - loss: 0.4284 - val_accuracy: 0.8073 - val_loss: 0.4183\n",
      "Epoch 13/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - accuracy: 0.8370 - loss: 0.3898 - val_accuracy: 0.8073 - val_loss: 0.4287\n",
      "Epoch 14/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - accuracy: 0.8534 - loss: 0.3795 - val_accuracy: 0.8177 - val_loss: 0.3960\n",
      "Epoch 15/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8466 - loss: 0.3497 - val_accuracy: 0.8177 - val_loss: 0.4068\n",
      "Epoch 16/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - accuracy: 0.8457 - loss: 0.3577 - val_accuracy: 0.8177 - val_loss: 0.4156\n",
      "Epoch 17/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - accuracy: 0.8335 - loss: 0.3426 - val_accuracy: 0.8333 - val_loss: 0.3962\n",
      "Epoch 18/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - accuracy: 0.8514 - loss: 0.3255 - val_accuracy: 0.8125 - val_loss: 0.4180\n",
      "Epoch 19/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - accuracy: 0.8730 - loss: 0.3054 - val_accuracy: 0.8385 - val_loss: 0.3720\n",
      "Epoch 20/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.8786 - loss: 0.2827 - val_accuracy: 0.8281 - val_loss: 0.4031\n",
      "Epoch 21/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - accuracy: 0.8711 - loss: 0.2953 - val_accuracy: 0.8073 - val_loss: 0.4094\n",
      "Epoch 22/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - accuracy: 0.8930 - loss: 0.2687 - val_accuracy: 0.7708 - val_loss: 0.4561\n",
      "Epoch 23/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - accuracy: 0.8680 - loss: 0.2958 - val_accuracy: 0.8385 - val_loss: 0.3707\n",
      "Epoch 24/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9103 - loss: 0.2337 - val_accuracy: 0.8125 - val_loss: 0.4223\n",
      "Epoch 25/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - accuracy: 0.8947 - loss: 0.2604 - val_accuracy: 0.8385 - val_loss: 0.3584\n",
      "Epoch 26/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.9050 - loss: 0.2272 - val_accuracy: 0.8333 - val_loss: 0.3857\n",
      "Epoch 27/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9099 - loss: 0.2075 - val_accuracy: 0.8490 - val_loss: 0.3684\n",
      "Epoch 28/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - accuracy: 0.9127 - loss: 0.2109 - val_accuracy: 0.8750 - val_loss: 0.3681\n",
      "Epoch 29/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - accuracy: 0.9212 - loss: 0.2054 - val_accuracy: 0.8073 - val_loss: 0.4797\n",
      "Epoch 30/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - accuracy: 0.9168 - loss: 0.2138 - val_accuracy: 0.8542 - val_loss: 0.3504\n",
      "Epoch 31/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - accuracy: 0.9186 - loss: 0.1883 - val_accuracy: 0.8802 - val_loss: 0.3454\n",
      "Epoch 32/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - accuracy: 0.9466 - loss: 0.1541 - val_accuracy: 0.8698 - val_loss: 0.3395\n",
      "Epoch 33/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9472 - loss: 0.1628 - val_accuracy: 0.8802 - val_loss: 0.3339\n",
      "Epoch 34/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - accuracy: 0.9573 - loss: 0.1410 - val_accuracy: 0.8490 - val_loss: 0.3690\n",
      "Epoch 35/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - accuracy: 0.9521 - loss: 0.1355 - val_accuracy: 0.8906 - val_loss: 0.3271\n",
      "Epoch 36/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - accuracy: 0.9578 - loss: 0.1314 - val_accuracy: 0.8906 - val_loss: 0.3140\n",
      "Epoch 37/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 59ms/step - accuracy: 0.9583 - loss: 0.1358 - val_accuracy: 0.8958 - val_loss: 0.3231\n",
      "Epoch 38/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9667 - loss: 0.1057 - val_accuracy: 0.8906 - val_loss: 0.3013\n",
      "Epoch 39/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - accuracy: 0.9650 - loss: 0.1061 - val_accuracy: 0.9062 - val_loss: 0.3381\n",
      "Epoch 40/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9644 - loss: 0.0968 - val_accuracy: 0.8906 - val_loss: 0.3392\n",
      "Epoch 41/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.9678 - loss: 0.0974 - val_accuracy: 0.8438 - val_loss: 0.3594\n",
      "Epoch 42/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9710 - loss: 0.0997 - val_accuracy: 0.9062 - val_loss: 0.3239\n",
      "Epoch 43/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9681 - loss: 0.0888 - val_accuracy: 0.8594 - val_loss: 0.3410\n",
      "Epoch 44/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9736 - loss: 0.0833 - val_accuracy: 0.8958 - val_loss: 0.3142\n",
      "Epoch 45/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.9872 - loss: 0.0641 - val_accuracy: 0.8854 - val_loss: 0.2991\n",
      "Epoch 46/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9819 - loss: 0.0815 - val_accuracy: 0.8854 - val_loss: 0.3457\n",
      "Epoch 47/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9877 - loss: 0.0576 - val_accuracy: 0.8906 - val_loss: 0.3164\n",
      "Epoch 48/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9959 - loss: 0.0502 - val_accuracy: 0.9115 - val_loss: 0.3310\n",
      "Epoch 49/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9775 - loss: 0.0697 - val_accuracy: 0.8698 - val_loss: 0.3204\n",
      "Epoch 50/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9892 - loss: 0.0544 - val_accuracy: 0.9219 - val_loss: 0.3235\n",
      "Epoch 51/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9814 - loss: 0.0531 - val_accuracy: 0.8854 - val_loss: 0.3266\n",
      "Epoch 52/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9947 - loss: 0.0372 - val_accuracy: 0.8698 - val_loss: 0.3258\n",
      "Epoch 53/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9900 - loss: 0.0449 - val_accuracy: 0.9010 - val_loss: 0.3212\n",
      "Epoch 54/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9934 - loss: 0.0381 - val_accuracy: 0.9115 - val_loss: 0.3306\n",
      "Epoch 55/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9977 - loss: 0.0308 - val_accuracy: 0.8750 - val_loss: 0.3466\n",
      "Epoch 56/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9933 - loss: 0.0336 - val_accuracy: 0.9115 - val_loss: 0.3072\n",
      "Epoch 57/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9961 - loss: 0.0266 - val_accuracy: 0.8958 - val_loss: 0.3274\n",
      "Epoch 58/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - accuracy: 0.9952 - loss: 0.0204 - val_accuracy: 0.9115 - val_loss: 0.3310\n",
      "Epoch 59/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.9971 - loss: 0.0240 - val_accuracy: 0.9010 - val_loss: 0.3228\n",
      "Epoch 60/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9958 - loss: 0.0199 - val_accuracy: 0.8958 - val_loss: 0.3379\n",
      "Epoch 61/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9996 - loss: 0.0138 - val_accuracy: 0.8854 - val_loss: 0.3280\n",
      "Epoch 62/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9980 - loss: 0.0185 - val_accuracy: 0.9167 - val_loss: 0.3421\n",
      "Epoch 63/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9985 - loss: 0.0157 - val_accuracy: 0.9062 - val_loss: 0.3384\n",
      "Epoch 64/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - accuracy: 0.9991 - loss: 0.0148 - val_accuracy: 0.9062 - val_loss: 0.3221\n",
      "Epoch 65/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.9062 - val_loss: 0.3366\n",
      "Epoch 66/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9994 - loss: 0.0131 - val_accuracy: 0.8958 - val_loss: 0.3548\n",
      "Epoch 67/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.8958 - val_loss: 0.3556\n",
      "Epoch 68/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.8646 - val_loss: 0.3953\n",
      "Epoch 69/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9940 - loss: 0.0218 - val_accuracy: 0.8854 - val_loss: 0.3798\n",
      "Epoch 70/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9986 - loss: 0.0127 - val_accuracy: 0.8906 - val_loss: 0.3735\n",
      "Epoch 71/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9115 - val_loss: 0.3442\n",
      "Epoch 72/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9062 - val_loss: 0.3468\n",
      "Epoch 73/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9010 - val_loss: 0.3457\n",
      "Epoch 74/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9062 - val_loss: 0.3474\n",
      "Epoch 75/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9062 - val_loss: 0.3524\n",
      "Epoch 76/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9062 - val_loss: 0.3620\n",
      "Epoch 77/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9062 - val_loss: 0.3531\n",
      "Epoch 78/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9062 - val_loss: 0.3540\n",
      "Epoch 79/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9010 - val_loss: 0.3655\n",
      "Epoch 80/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9062 - val_loss: 0.3581\n",
      "Epoch 81/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9062 - val_loss: 0.3661\n",
      "Epoch 82/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9062 - val_loss: 0.3635\n",
      "Epoch 83/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9010 - val_loss: 0.3656\n",
      "Epoch 84/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9062 - val_loss: 0.3634\n",
      "Epoch 85/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9062 - val_loss: 0.3677\n",
      "Epoch 86/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9062 - val_loss: 0.3660\n",
      "Epoch 87/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9062 - val_loss: 0.3717\n",
      "Epoch 88/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9062 - val_loss: 0.3717\n",
      "Epoch 89/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9062 - val_loss: 0.3736\n",
      "Epoch 90/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9115 - val_loss: 0.3698\n",
      "Epoch 91/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9062 - val_loss: 0.3806\n",
      "Epoch 92/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9062 - val_loss: 0.3779\n",
      "Epoch 93/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9062 - val_loss: 0.3768\n",
      "Epoch 94/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9115 - val_loss: 0.3808\n",
      "Epoch 95/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9062 - val_loss: 0.3798\n",
      "Epoch 96/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9062 - val_loss: 0.3813\n",
      "Epoch 97/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9062 - val_loss: 0.3857\n",
      "Epoch 98/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9062 - val_loss: 0.3870\n",
      "Epoch 99/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9115 - val_loss: 0.3942\n",
      "Epoch 100/100\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9062 - val_loss: 0.3904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x178c2727850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:39:48.191638Z",
     "start_time": "2024-09-23T12:39:47.799722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.90625\n",
      "Test loss: 0.39043334126472473\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:39:48.565965Z",
     "start_time": "2024-09-23T12:39:48.351617Z"
    }
   },
   "cell_type": "code",
   "source": "model.save('tic-tac-toe.model.keras')",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions\n",
    "\n",
    "Now load your saved model and use it to make predictions on a few random rows in the test dataset. Check if the predictions are correct."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:39:50.044870Z",
     "start_time": "2024-09-23T12:39:48.870704Z"
    }
   },
   "cell_type": "code",
   "source": "model = load_model('tic-tac-toe.model.keras') ",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:39:50.623703Z",
     "start_time": "2024-09-23T12:39:50.088782Z"
    }
   },
   "cell_type": "code",
   "source": "prediction = model.predict([X_test])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step  \n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:39:51.356998Z",
     "start_time": "2024-09-23T12:39:50.783100Z"
    }
   },
   "cell_type": "code",
   "source": "model.predict(X_test)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.74276283e-06, 9.99996185e-01, 1.00475887e-07],\n",
       "       [9.30299878e-01, 6.96996972e-02, 4.77364779e-07],\n",
       "       [1.00000000e+00, 3.58286995e-13, 1.27252801e-14],\n",
       "       [1.00000000e+00, 5.98939609e-09, 3.08856517e-11],\n",
       "       [3.12566328e-07, 9.99999642e-01, 2.76812635e-08],\n",
       "       [9.88651276e-01, 1.13482466e-02, 5.16907960e-07],\n",
       "       [9.22536012e-03, 9.90772247e-01, 2.44111789e-06],\n",
       "       [9.99999642e-01, 3.23838151e-07, 4.42773707e-10],\n",
       "       [1.39539884e-02, 9.86043930e-01, 2.13738508e-06],\n",
       "       [9.87796605e-01, 1.22024873e-02, 9.24563039e-07],\n",
       "       [9.99996901e-01, 3.07422579e-06, 1.63591647e-08],\n",
       "       [4.19396628e-07, 9.99999523e-01, 1.09986978e-07],\n",
       "       [9.99998093e-01, 1.94400445e-06, 3.80076548e-09],\n",
       "       [1.07764319e-01, 8.92226458e-01, 9.25636596e-06],\n",
       "       [2.65365649e-08, 1.00000000e+00, 1.51680790e-09],\n",
       "       [1.86422335e-06, 9.99998093e-01, 6.18992786e-08],\n",
       "       [3.24492212e-05, 9.99966025e-01, 1.50138703e-06],\n",
       "       [2.47921753e-06, 9.99996543e-01, 9.42652150e-07],\n",
       "       [1.15374901e-08, 1.00000000e+00, 1.38756802e-08],\n",
       "       [1.00000000e+00, 9.33992526e-16, 1.99792216e-16],\n",
       "       [7.01943250e-08, 9.99999881e-01, 9.44798515e-08],\n",
       "       [1.00000000e+00, 1.55907093e-11, 7.05540281e-13],\n",
       "       [1.65724324e-03, 9.98315930e-01, 2.67888863e-05],\n",
       "       [5.78920394e-02, 9.42098379e-01, 9.58492001e-06],\n",
       "       [1.58828584e-07, 9.99999881e-01, 1.89534379e-08],\n",
       "       [9.98478353e-01, 1.52093172e-03, 7.17490991e-07],\n",
       "       [8.70756447e-01, 1.29242480e-01, 1.03520415e-06],\n",
       "       [5.65876835e-04, 9.99433339e-01, 7.82865413e-07],\n",
       "       [1.41350820e-03, 9.98580694e-01, 5.85727548e-06],\n",
       "       [5.47660049e-03, 9.94522810e-01, 5.45486387e-07],\n",
       "       [1.39228906e-09, 1.00000000e+00, 3.93790917e-10],\n",
       "       [4.68986800e-05, 9.99952912e-01, 1.50470939e-07],\n",
       "       [3.17249237e-06, 9.99996781e-01, 2.18788774e-08],\n",
       "       [9.99999881e-01, 1.48218263e-07, 1.15778243e-09],\n",
       "       [2.14875990e-06, 9.99997616e-01, 2.15779863e-07],\n",
       "       [4.51058328e-01, 5.48913658e-01, 2.80132572e-05],\n",
       "       [1.43589735e-01, 8.56409848e-01, 4.41645682e-07],\n",
       "       [9.29903030e-01, 7.00959116e-02, 9.91400270e-07],\n",
       "       [6.04657084e-03, 9.93951082e-01, 2.40705367e-06],\n",
       "       [5.43250280e-06, 9.99994516e-01, 6.47949605e-08],\n",
       "       [7.45104917e-05, 9.99923110e-01, 2.42364172e-06],\n",
       "       [1.53230329e-03, 9.98467147e-01, 5.08950109e-07],\n",
       "       [1.00000000e+00, 2.61523858e-11, 4.39673742e-13],\n",
       "       [3.48543611e-10, 1.00000000e+00, 8.02674871e-10],\n",
       "       [1.57951499e-10, 1.00000000e+00, 5.61101032e-09],\n",
       "       [8.10015559e-01, 1.89979941e-01, 4.41157545e-06],\n",
       "       [1.00000000e+00, 4.44517867e-10, 4.71755317e-12],\n",
       "       [7.72373304e-02, 9.22759354e-01, 3.30091484e-06],\n",
       "       [1.50588576e-05, 9.99984741e-01, 1.62115896e-07],\n",
       "       [1.00859422e-02, 9.89912868e-01, 1.19239098e-06],\n",
       "       [9.99718845e-01, 2.80943845e-04, 2.17513858e-07],\n",
       "       [1.87050791e-05, 9.99981284e-01, 6.39498836e-08],\n",
       "       [3.49214213e-04, 9.99650478e-01, 2.56533923e-07],\n",
       "       [4.37210202e-02, 9.56268787e-01, 1.01236783e-05],\n",
       "       [1.10449332e-06, 9.99998808e-01, 3.68481636e-08],\n",
       "       [2.06351870e-05, 9.99979258e-01, 8.64565521e-08],\n",
       "       [9.99415278e-01, 5.84569003e-04, 1.24343941e-07],\n",
       "       [6.95088384e-05, 9.99930382e-01, 7.56072538e-08],\n",
       "       [9.87271154e-10, 1.00000000e+00, 2.89172490e-08],\n",
       "       [2.76048784e-04, 9.99723494e-01, 4.82886719e-07],\n",
       "       [2.78569781e-03, 9.97213900e-01, 4.26769304e-07],\n",
       "       [9.99999285e-01, 7.30368583e-07, 2.11811146e-09],\n",
       "       [3.49497697e-09, 1.00000000e+00, 2.04236139e-09],\n",
       "       [9.55554008e-01, 4.44455929e-02, 3.78245602e-07],\n",
       "       [5.67486968e-05, 9.99943256e-01, 2.95973699e-08],\n",
       "       [3.20394456e-01, 6.79601908e-01, 3.57350405e-06],\n",
       "       [2.00456086e-07, 9.99999762e-01, 7.24375493e-09],\n",
       "       [9.99975801e-01, 2.42553488e-05, 4.94799366e-08],\n",
       "       [1.27811179e-01, 8.72187614e-01, 1.25481756e-06],\n",
       "       [4.35591474e-08, 1.00000000e+00, 1.34721843e-08],\n",
       "       [8.52514422e-05, 9.99895930e-01, 1.88480008e-05],\n",
       "       [9.56201106e-02, 9.04379189e-01, 6.80376559e-07],\n",
       "       [6.09217468e-11, 1.00000000e+00, 3.34818062e-09],\n",
       "       [4.41760894e-05, 9.99955773e-01, 8.08441953e-08],\n",
       "       [1.30130712e-10, 1.00000000e+00, 2.72845940e-10],\n",
       "       [3.16861502e-07, 9.99999642e-01, 1.14458230e-08],\n",
       "       [2.13515843e-04, 9.99786317e-01, 2.11011482e-07],\n",
       "       [1.09236598e-01, 8.90758932e-01, 4.46297827e-06],\n",
       "       [1.59903102e-05, 9.99983788e-01, 2.16590408e-07],\n",
       "       [6.57905872e-08, 9.99999881e-01, 8.93123975e-09],\n",
       "       [1.00000000e+00, 1.24023318e-12, 7.88043540e-14],\n",
       "       [7.89097161e-04, 9.99210000e-01, 9.27300619e-07],\n",
       "       [1.47380587e-03, 9.98524964e-01, 1.20131097e-06],\n",
       "       [9.99999881e-01, 6.80599825e-08, 1.00144920e-10],\n",
       "       [1.14539671e-06, 9.99998569e-01, 2.31221108e-07],\n",
       "       [2.44735456e-05, 9.99975443e-01, 1.09103652e-07],\n",
       "       [9.99985099e-01, 1.49456209e-05, 1.41116798e-08],\n",
       "       [9.99934196e-01, 6.57863638e-05, 3.53708351e-08],\n",
       "       [9.99585569e-01, 4.14431212e-04, 5.23514530e-08],\n",
       "       [4.23221350e-01, 5.76765895e-01, 1.27222547e-05],\n",
       "       [9.97969449e-01, 2.02929275e-03, 1.22327185e-06],\n",
       "       [9.82927144e-01, 1.70724783e-02, 3.75169577e-07],\n",
       "       [2.36565884e-05, 9.99976039e-01, 2.52261941e-07],\n",
       "       [2.62567550e-02, 9.73740935e-01, 2.30910268e-06],\n",
       "       [9.96185839e-01, 3.81412427e-03, 5.22901580e-08],\n",
       "       [3.65142014e-08, 1.00000000e+00, 4.97610753e-09],\n",
       "       [9.98163760e-01, 1.83628837e-03, 3.55222696e-08],\n",
       "       [1.08346520e-02, 9.89149392e-01, 1.59788506e-05],\n",
       "       [9.99999762e-01, 1.83309140e-07, 4.51138266e-10],\n",
       "       [7.51831375e-11, 1.00000000e+00, 3.97688993e-09],\n",
       "       [2.43690029e-05, 9.99974728e-01, 9.41083044e-07],\n",
       "       [1.57240629e-01, 8.42753828e-01, 5.51474841e-06],\n",
       "       [6.54995322e-01, 3.45003098e-01, 1.45731849e-06],\n",
       "       [1.74827042e-10, 1.00000000e+00, 7.68383246e-10],\n",
       "       [9.99998689e-01, 1.31848969e-06, 1.39733709e-08],\n",
       "       [9.99980807e-01, 1.92480838e-05, 1.27382362e-08],\n",
       "       [1.91127047e-01, 8.08872342e-01, 6.61499996e-07],\n",
       "       [9.99942780e-01, 5.72340796e-05, 9.57316448e-09],\n",
       "       [1.00137051e-07, 9.99999881e-01, 7.88894616e-10],\n",
       "       [2.88273627e-03, 9.97117162e-01, 1.58532572e-07],\n",
       "       [3.12284820e-09, 1.00000000e+00, 5.42258194e-09],\n",
       "       [2.58798227e-05, 9.99972463e-01, 1.65110328e-06],\n",
       "       [7.04550326e-01, 2.95447677e-01, 2.00751151e-06],\n",
       "       [2.63804896e-03, 9.97360647e-01, 1.34876859e-06],\n",
       "       [2.55530286e-09, 1.00000000e+00, 2.15485652e-09],\n",
       "       [9.99999881e-01, 1.40271752e-07, 5.59625164e-08],\n",
       "       [9.98475015e-01, 1.52318168e-03, 1.76835511e-06],\n",
       "       [1.00000000e+00, 6.04034267e-10, 1.31610917e-10],\n",
       "       [1.00000000e+00, 1.22533670e-13, 1.29475356e-14],\n",
       "       [8.03670406e-01, 1.96329102e-01, 4.39734947e-07],\n",
       "       [1.36168888e-02, 9.86382604e-01, 5.30608872e-07],\n",
       "       [6.90060493e-04, 9.99307990e-01, 1.92306106e-06],\n",
       "       [1.29500730e-02, 9.87046599e-01, 3.32612626e-06],\n",
       "       [6.43495878e-04, 9.99354184e-01, 2.29596048e-06],\n",
       "       [1.78452666e-07, 9.99999762e-01, 4.98359292e-08],\n",
       "       [5.07957475e-06, 9.99994874e-01, 9.36504918e-08],\n",
       "       [6.76852226e-01, 3.23111117e-01, 3.66613749e-05],\n",
       "       [1.56707466e-01, 8.43075514e-01, 2.17069944e-04],\n",
       "       [9.99999881e-01, 1.78283102e-07, 1.64172134e-10],\n",
       "       [5.39661341e-05, 9.99945045e-01, 1.02427600e-06],\n",
       "       [8.49889964e-03, 9.91500854e-01, 2.11508123e-07],\n",
       "       [6.45354867e-01, 3.54624420e-01, 2.07291632e-05],\n",
       "       [7.14121666e-03, 9.92837012e-01, 2.18111072e-05],\n",
       "       [9.99996424e-01, 3.53037831e-06, 1.68917136e-09],\n",
       "       [9.98970866e-01, 1.02903543e-03, 7.36279091e-08],\n",
       "       [1.00000000e+00, 1.50490488e-11, 1.44470655e-12],\n",
       "       [1.96556630e-05, 9.99979615e-01, 7.69753456e-07],\n",
       "       [1.33391679e-03, 9.98665571e-01, 5.69720669e-07],\n",
       "       [2.87198299e-03, 9.97127831e-01, 1.84025581e-07],\n",
       "       [1.06833483e-07, 9.99999881e-01, 7.04425540e-09],\n",
       "       [9.92768049e-01, 7.23081082e-03, 1.13962699e-06],\n",
       "       [5.54317259e-10, 1.00000000e+00, 1.10941767e-09],\n",
       "       [2.12866100e-04, 9.99786556e-01, 5.55915904e-07],\n",
       "       [1.62716663e-06, 9.99998331e-01, 3.76922706e-08],\n",
       "       [7.54738271e-01, 2.45225891e-01, 3.57952122e-05],\n",
       "       [4.42327810e-08, 9.99999881e-01, 2.41285179e-08],\n",
       "       [1.94021582e-03, 9.98058736e-01, 9.85666247e-07],\n",
       "       [1.91090643e-04, 9.99808848e-01, 2.56321524e-08],\n",
       "       [1.26589894e-05, 9.99987245e-01, 9.04516995e-08],\n",
       "       [3.53455507e-05, 9.99964356e-01, 3.17987599e-07],\n",
       "       [2.47909711e-03, 9.97520506e-01, 4.25061842e-07],\n",
       "       [5.88747571e-05, 9.99940753e-01, 3.22447761e-07],\n",
       "       [1.90090737e-03, 9.98097599e-01, 1.50649305e-06],\n",
       "       [3.02062224e-04, 9.99697685e-01, 2.23430774e-07],\n",
       "       [9.99992847e-01, 7.11124176e-06, 1.53907145e-08],\n",
       "       [3.72671275e-05, 9.99961138e-01, 1.60430795e-06],\n",
       "       [9.99673486e-01, 3.26443871e-04, 1.39694990e-07],\n",
       "       [7.12551296e-01, 2.87447840e-01, 8.22275524e-07],\n",
       "       [2.53771537e-09, 1.00000000e+00, 4.58116256e-09],\n",
       "       [1.00000000e+00, 1.50359715e-14, 1.11158759e-15],\n",
       "       [1.28827810e-01, 8.71156871e-01, 1.53373294e-05],\n",
       "       [9.99999046e-01, 9.47719400e-07, 2.52406140e-09],\n",
       "       [2.78640818e-03, 9.97039378e-01, 1.74144967e-04],\n",
       "       [2.79379464e-07, 9.99999642e-01, 3.13993063e-08],\n",
       "       [1.00000000e+00, 2.93872843e-10, 4.98936743e-12],\n",
       "       [4.12284970e-01, 5.87671816e-01, 4.31792323e-05],\n",
       "       [7.95303378e-03, 9.92037654e-01, 9.29780617e-06],\n",
       "       [9.92520213e-01, 7.47975241e-03, 3.95616020e-08],\n",
       "       [5.70943683e-08, 9.99999881e-01, 7.34439993e-08],\n",
       "       [1.08805962e-01, 8.91190708e-01, 3.33671483e-06],\n",
       "       [1.62463933e-02, 9.83751893e-01, 1.70049202e-06],\n",
       "       [3.36788036e-02, 9.66318369e-01, 2.80551262e-06],\n",
       "       [6.43702806e-04, 9.99355733e-01, 6.08053938e-07],\n",
       "       [3.43731554e-05, 9.99961734e-01, 3.92097490e-06],\n",
       "       [3.13521654e-04, 9.99686360e-01, 1.35860034e-07],\n",
       "       [9.96893287e-01, 3.10627557e-03, 4.11210948e-07],\n",
       "       [8.69913399e-01, 1.30085081e-01, 1.51438019e-06],\n",
       "       [1.00000000e+00, 2.20483961e-12, 8.99381887e-14],\n",
       "       [2.77328324e-02, 9.72265661e-01, 1.51971983e-06],\n",
       "       [9.99994636e-01, 5.40609381e-06, 1.93739584e-08],\n",
       "       [1.00000000e+00, 1.32711309e-09, 3.64641607e-12],\n",
       "       [1.00000000e+00, 1.71233551e-13, 4.50366266e-14],\n",
       "       [6.72321813e-03, 9.93273973e-01, 2.76622882e-06],\n",
       "       [6.59344869e-06, 9.99993205e-01, 1.91408844e-07],\n",
       "       [5.30507077e-06, 9.99994516e-01, 1.87567537e-07],\n",
       "       [1.00000000e+00, 5.67191272e-09, 1.82878837e-10],\n",
       "       [6.86696544e-02, 9.31325614e-01, 4.78081074e-06],\n",
       "       [7.63701200e-01, 2.36295015e-01, 3.72559543e-06],\n",
       "       [1.10924361e-06, 9.99998927e-01, 1.74722317e-08],\n",
       "       [6.60249556e-04, 9.99336302e-01, 3.43307443e-06],\n",
       "       [1.02949382e-09, 1.00000000e+00, 1.51568291e-09],\n",
       "       [9.99999762e-01, 2.41858714e-07, 8.85250762e-10]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improve Your Model\n",
    "\n",
    "Did your model achieve low loss (<0.1) and high accuracy (>0.95)? If not, try to improve your model.\n",
    "\n",
    "But how? There are so many things you can play with in Tensorflow and in the next challenge you'll learn about these things. But in this challenge, let's just do a few things to see if they will help.\n",
    "\n",
    "* Add more layers to your model. If the data are complex you need more layers. But don't use more layers than you need. If adding more layers does not improve the model performance you don't need additional layers.\n",
    "* Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want. Then pass the instance to `model.compile` as the optimizer.\n",
    "    * `tf.keras.optimizers.Adam` [reference](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
    "    * Don't worry if you don't understand what the learning rate does. You'll learn about it in the next challenge.\n",
    "* Adjust the number of epochs when you fit the training data to the model. Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:47:45.374358Z",
     "start_time": "2024-09-23T10:46:57.850001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in [0.0001, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10.0]:\n",
    "  print(i)\n",
    "\n",
    "  model = Sequential()\n",
    "  \n",
    "  # Input layer: Matches the size of your input data (flattened Tic-Tac-Toe board)\n",
    "  model.add(Dense(40, activation='relu'))\n",
    "  \n",
    "  # Hidden layer(s): Experiment with the number of neurons and layers\n",
    "  model.add(Dense(40, activation='relu'))\n",
    "  model.add(Dense(40, activation='relu'))\n",
    "  model.add(Dense(40, activation='relu'))\n",
    "  \n",
    "  # Output layer: Number of neurons = number of classes (possible outcomes in Tic-Tac-Toe)\n",
    "  model.add(Dense(3, activation='softmax'))\n",
    "  \n",
    "  opt = keras.optimizers.Adam(learning_rate=i)\n",
    "  \n",
    "  model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
    "  model.fit(X_train, y_train, epochs=95, batch_size=32, validation_data=(X_test, y_test), verbose=False) \n",
    "  \n",
    "  test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "  print('Test accuracy:', test_acc)\n",
    "  print('Test loss:', test_loss)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Test accuracy: 0.890625\n",
      "Test loss: 0.31355908513069153\n"
     ]
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Test accuracy: 0.8958333134651184\n",
    "Test loss: 0.34641408920288086"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which approach(es) did you find helpful to improve your model performance?**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:49:42.597514Z",
     "start_time": "2024-09-23T12:48:39.131008Z"
    }
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Create the optimizer instance\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=110, batch_size=17, validation_data=(X_test, y_test), verbose=False)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(loss, accuracy)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9808 - loss: 0.0648 \n",
      "0.06850503385066986 0.9739583134651184\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "epoch 120 | batch 24: 0.21556060016155243 0.9635416865348816\n",
    "\n",
    "epoch 120 | batch 18: 0.14408843219280243 0.9791666865348816\n",
    "\n",
    "epoch 120 | batch 17: 0.10755687206983566 0.9739583134651184\n",
    "\n",
    "epoch 110 | batch 17: 0.06850503385066986 0.9739583134651184\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
